model_checkpoint_eval:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: validation/overall_cross_entropy # name of the logged metric which determines when model is improving
  mode: "min" # "max" means higher metric value is better, can be also "min"
  save_top_k: 1 # save k best models (determined by above metric)
  save_last: True # additionaly always save model from last epoch
  verbose: False
  dirpath: "${current_experiment_dir}/checkpoints/"
  filename: "eval_epoch_{epoch:03d}"
  auto_insert_metric_name: False

model_checkpoint_train:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: training/overall_cross_entropy
  save_on_train_epoch_end: True
  save_top_k: 1
  save_last: true
  every_n_train_steps: 250
  mode: "min"
  verbose: False
  dirpath: "${current_experiment_dir}/checkpoints/"
  filename: "train_epoch_{epoch:03d}"
  auto_insert_metric_name: False

model_summary:
  _target_: pytorch_lightning.callbacks.RichModelSummary
  max_depth: 5

rich_progress_bar:
  _target_: pytorch_lightning.callbacks.RichProgressBar

learning_rate_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: "step"

gs_file_monitor:
  _target_: base.callbacks.cloud_storage_callbacks.GoogleStorageBucketRSyncClient
  bucket_name: 'tali-experiments'
  experiments_root_dir: ${current_experiment_dir}
  experiment_name: ${name}
  exclude_list: [.git/*]
  options_list: ['r', 'd', 'u', 'e']
  resume: ${resume}